<app-sub-title>Introduction</app-sub-title>

<app-paragraph>Hello! In this section we will go step by step through the process of building a Machine Learning algorithm dedicated to predict the supervenience of each passenger of the Titanic.</app-paragraph>

<app-paragraph>To achieve this final goal, we will go through certain stages following the "Cross Industry Standard Process for Data Mining," or in other words, the CRISP-DM. So by way of summary, we will look at the following:</app-paragraph>

<ul>
    <app-list-item>Understanding the business and the data.</app-list-item>
    <app-list-item>Data preparation.</app-list-item>
    <app-list-item>Modeling.</app-list-item>
    <app-list-item>Evaluation.</app-list-item>
</ul>

<app-paragraph>First we will base our explanation and build the model using RapidMiner, then we will do the same steps of selection and modeling in Python, to finally compare both results and reach a conclusion.</app-paragraph>

<app-paragraph>Let's get to work!</app-paragraph>

<app-sub-title>Understanding the "business" and the data.</app-sub-title>

<app-mini-sub-title>The "business"</app-mini-sub-title>

<app-paragraph>When we talk about understanding the "business," we mean understanding the problem/situation we are analyzing. For this, it can be very useful to ask questions such as:</app-paragraph>

<ul>
    <app-list-item>What problem does the data translate?</app-list-item>
    <app-list-item>Do I understand the problem I am trying to solve?</app-list-item>
    <app-list-item>What does my data represent?</app-list-item>
    <app-list-item>What do I want to do/predict?</app-list-item>
</ul>

<app-paragraph>In this case, since we are working on a known problem/event, it is easy to understand the "business." Our intention is to predict the survival of an individual in the catastrophe of the sinking of the ship "Titanic," so we are facing a classification problem (survive or not).</app-paragraph>

<app-mini-sub-title>The data</app-mini-sub-title>

<app-paragraph>Our current dataset represents in each of its tuples the data of a passenger, each tuple has a total of 12 attributes which have different types and domains. We have:</app-paragraph>

<ul>
    <app-list-item>PassengerId: A unique identifier given to each tuple of the dataset. Type: numeric.</app-list-item>
    <app-list-item>Survived: Indicates whether the passenger in question survived or not. Type: binomial numeric with value 1 (survived) or 0 (did not survive) (This is our target variable).</app-list-item>
    <app-list-item>Pclass: The class in which the passenger was traveling. Type: numeric with 3 possible values, 1 (first class), 2 (second class), 3 (third class).</app-list-item>
    <app-list-item>Name: The passenger's name. Type: categorical.</app-list-item>
    <app-list-item>Sex: The passenger's sex. Type: binomial categorical with value "male" (if male) or "female" (if female).</app-list-item>
    <app-list-item>Age: The passenger's age. Type: numeric, integer.</app-list-item>
    <app-list-item>SibSp: The number of siblings or spouses of the passenger, on board. Type: numeric.</app-list-item>
    <app-list-item>Parch: The number of parents or children of the passenger, on board. Type: numeric.</app-list-item>
    <app-list-item>Ticket11: The passenger's ticket number. Type: categorical.</app-list-item>
    <app-list-item>Fare: The price of the ticket paid by the passenger. Type: numeric.</app-list-item>
    <app-list-item>Cabin: The passenger's cabin number. Type: categorical.</app-list-item>
    <app-list-item>Embarked: The port where the passenger embarked. Type: categorical with 3 possible values, "C" (Cherbourg), "Q" (Queenstown), "S" (Southampton).</app-list-item>
</ul>

<app-paragraph>With all the recognized data, we can make a preliminary analysis and propose some hypotheses about them in their usefulness in predicting our target variable.</app-paragraph>

<app-paragraph>For example, it seems sensible to say that the passenger's name is not a data that provides much information to determine his survival. On the other hand, it seems that age or sex may play a role, based on the "women and children first in the boats" scoop.</app-paragraph>

<app-paragraph>But, at the end of the day, it is when we make use of *cleansing* and attribute selection tactics that we will be able to know more reliably which attributes will have a certain level of performance when applied by our model.</app-paragraph>

<app-paragraph>Knowing a little about the context of our problem, what we want to do, and what we currently have, we can proceed with our modeling process, the preparation of our data.</app-paragraph>

<app-paragraph>When preparing our data, it is useful to have at hand those issues to which we have to pay attention, such as:</app-paragraph>

<ul>
    <app-list-item>Presence of *missing values.</app-list-item>
    <app-list-item>Presence of outliers.</app-list-item>
    <app-list-item>The distribution of our data.</app-list-item>
    <app-list-item>The scale of our data.</app-list-item>
</ul>

<app-paragraph>These are just some of the most common issues to which we have to pay attention when preparing our data. Of course, depending on the algorithm(s) we use, and the problem we are trying to solve, we will be more or less robust to the presence of some of them, or we will give more or less importance to some of them (for example, the case of fraud detection).</app-paragraph>

<app-paragraph>Let's go to RapidMiner and see the "quality" of our dataset.</app-paragraph>

<app-image [image]="'../../../../../assets/titanic-1.png'"></app-image>

<app-paragraph>In the first instance, we can see that the "Cabin" attribute has quite a lot of missing data. On the other hand, "age" also has some missing data, but in this first visualization, it seems to be much less than "Cabin".</app-paragraph>

<app-paragraph>If we get the statistics of all our attributes, we will see that:</app-paragraph>

<app-image [image]="'../../../../../assets/titanic-2.png'"></app-image>

<app-paragraph>There are indeed some attributes with missing values, more specifically they are:</app-paragraph>

<ul>
    <app-list-item>"Age" with 177 missing values.</app-list-item>
    <app-list-item>"Cabin" with 687 missing values.</app-list-item>
    <app-list-item>"Embarked" with 2 missing values.</app-list-item>
</ul>

<app-paragraph>On the other hand, if we want to analyze the presence of outliers, we should first determine which of the current attributes are candidates for this type of problem. For example, the attribute "Survived," which is a binomial, cannot have outlier data because its only possible values are 1 and 0, and in this case this characteristic is being fulfilled, the same happens with the attribute "Pclass," for example.</app-paragraph>

<app-paragraph>Likewise, the attribute that represents the names of the passengers ("Name") will not be able to have outlier data either, especially because it is not a numeric data.</app-paragraph>

<app-paragraph>If we continue to apply the same ideas for the rest of the data, we will obtain that the candidates we should pay attention to if we are looking for outliers are:</app-paragraph>

<ul>
    <app-list-item>"Age"</app-list-item>
    <app-list-item>"SibSp"</app-list-item>
    <app-list-item>"Parch"</app-list-item>
    <app-list-item>"Fare"</app-list-item>
</ul>

<app-paragraph>So, having obtained those data, what we have to do now is to analyze them carefully. A good initial visualization is to look at the minimum, maximum, and average values, so by selecting the attributes, we get that:</app-paragraph>

<app-image [image]="'../../../../../assets/titanic-3.png'"></app-image>

<app-paragraph>We see that, for example, the "Age" attribute, while having a maximum value of 80, averages about 30, which is not that far off. In addition, we can see the mini bar chart provided which roughly indicates the most common ages, which agrees with the calculations mentioned above, as we can see how the popularity of data is centered between the values of 15~20 and ~40, while the higher the age, the less occurrences of the same there are. We can say then that, although this attribute has data somewhat far apart, it is not such an alarming situation.</app-paragraph>

<app-paragraph>On the other hand, if we go to the attributes of "SibSp" and "Parch," which have a similar behavior between them, we see, thanks to the graphs presented that the great majority of data in the attributes is in the minimum value of 0, having a maximum of 8 for the case of "SibSp," and 6 for the case of "Parch." In addition, we see that in general the average value in both cases is very far from the highest values, being the average of "SibSp" 0.523 and that of "Parch" 0.382. Although, although it seems a call for attention, we must take into account the meaning of the data. In this case, as mentioned above, these attributes represent the number of passengers "related" in some way or another to a certain passenger, which must be taken into account in the final analysis.</app-paragraph>

<app-paragraph>Finally, being the most differentiating case, we obtain that the attribute "Fare" does have outliers. We say this because we see that the minimum value in this case is 0, while the maximum is 512.329, being the average 32.204. This denotes that the maximum value of this attribute is an outlier. In addition, if we pay attention to the graphs, we also see that there are some data with values between 200,000 and 300,000 which are considerably high compared to the majority of data, which is located between 0 and 20,000. So we conclude that outliers are present in this attribute, which we will have to resolve.</app-paragraph>

<app-paragraph>A very useful tool to visualize the distribution of our data are the graphs, in this case, if we make use of the "Scatter" graph we will be able to see in a better way the points that are farther away from the popular values. In the following we apply this visualization for the "Fare" attribute:</app-paragraph>

<app-image [image]="'../../../../../assets/titanic-4.png'"></app-image>

<app-paragraph>We see then that there are some points (highlighted in the red box in the image) that are quite far from the normal values.</app-paragraph>

<app-paragraph>Moreover, if we make use of the "Detect Outlier" operator offered by RapidMiner, we can see how the cases framed in the box are detected:</app-paragraph>

<app-image [image]="'../../../../../assets/titanic-5.png'"></app-image>

<app-paragraph>The points colored in green are those that were classified as "outliers," while those in blue are those that were not (note that for the "Detect Outlier" operator, the parameter indicating the number of "outliers" to be detected was initialized to 10, its default value).</app-paragraph>

<app-paragraph>This type of visualizations/tools helps us to have an initial determination of the number of "outliers," which will be very useful when correcting this issue.</app-paragraph>

<app-paragraph>The same we did with the "Fare" attribute we can do with the rest of the attributes we consider, to determine more accurately the amount and presence of "outliers."</app-paragraph>

<app-paragraph>Closely related to outlier analysis is the distribution analysis of our data. Some of this we have already been talking about (without explicitly mentioning it) when we were analyzing, with the graphs, the presence of outliers in the attributes:</app-paragraph>

<ul>
    <app-list-item>"Age"</app-list-item>
    <app-list-item>"SibSp"</app-list-item>
    <app-list-item>"Parch"</app-list-item>
    <app-list-item>"Fare"</app-list-item>
</ul>

<app-paragraph>We must remember that it is beneficial to have a normal distribution (Gaussian) in our data, since it would alter some models that we can eventually use. If we analyze some distributions of the aforementioned attributes, with, for example, a histogram, we will see that for the case of "Age," we do have a more or less normal distribution:</app-paragraph>

<app-image [image]="'../../../../../assets/titanic-6.png'"></app-image>

<app-paragraph>Although it is not quite perfect, it is close to what we want.</app-paragraph>

<app-paragraph>The opposite is the case for the "Fare" attribute, which, as we have already seen, has a rather skewed distribution:</app-paragraph>

<app-image [image]="'../../../../../assets/titanic-7.png'"></app-image>

<app-paragraph>This must be taken into account when using our data, as it could affect the performance of some models, so we will have to consider transforming them.</app-paragraph>

<app-paragraph>Finally, a point also to consider is the scale at which our data is found because many algorithms are sensitive to this point, and if there is an uneven scale, the performance could be affected.</app-paragraph>

<app-paragraph>A great visualization tool to see the scale of our data is the "boxplot" graph, such that by applying it we will obtain:</app-paragraph>

<app-image [image]="'../../../../../assets/titanic-8.png'"></app-image>

<app-paragraph>At first glance it is noticeable that there is an uneven distribution in the corresponding attributes (which are the numerical ones), so normalizing them will be a point to consider.</app-paragraph>

<app-sub-title>Connecting all the dots</app-sub-title>

<app-paragraph>As a summary of everything we have been talking about so far, we can say that:</app-paragraph>

<ul>
    <app-list-item>Missings values: If there is presence of missing values in the attributes "Age", "Cabin", "Embarked".</app-list-item>
    <app-list-item>Outliers: If outliers are present, especially in "Fare", "SibSp", "Parch" attributes.</app-list-item>
    <app-list-item>Distribution: Attributes such as "Fare", "SibSp", "Parch" present a quite marked non-normal distribution.</app-list-item>
    <app-list-item>Scale: Numeric attributes "Age", "SibSp", "Parch", "Fare" have different scaling.</app-list-item>
</ul>

<app-sub-title>Preparing the dataset</app-sub-title>

<app-mini-sub-title>Missings</app-mini-sub-title>

<app-paragraph>First of all, it is always advisable to take care of the missings values. As much as possible we will try to avoid discarding as much as possible the tuples/records that we have, since the data is a very limited and too important resource.</app-paragraph>

<app-paragraph>With this premise, for the case of the missing values of the attribute "Age", since they are relatively few (in comparison with the total volume of the dataset), what we can do is to use a strategy to impute data in these records. A very basic one, and quite often used, is to replace the missing ones by the total average of the attribute.</app-paragraph>

<app-paragraph>On the other hand, for the case of "Embarked" which has only 2 missing values, we could replace them by the mode value (s).</app-paragraph>

<app-paragraph>Finally we have the case of "Cabin", the most complicated one. "Cabin", as mentioned above, has a large number of missing values, in fact, very little of the data of this attribute has values. In a situation like this, where there is not enough information to perform any transformation, the most sensible thing to do would be to discard the use of this attribute.</app-paragraph>

<app-paragraph>Knowing everything we have to do, the only thing left to do is to do it! This is how in RapidMiner we obtain:</app-paragraph>

<app-image [image]="'../../../../../assets/titanic-9.png'"></app-image>

<app-callout>Note that the rule for the process is an exclusion rule, and that we exclude the "Passengerid" attribute because it is not a piece of data that contributes any information to our problem, it is simply an identifier.</app-callout>

<app-paragraph>Now, to replace the missing values, what we must do is:</app-paragraph>

<app-image [image]="'../../../../../assets/titanic-10.png'"></app-image>

<app-paragraph>The resulting dataset at this point is:</app-paragraph>

<app-image [image]="'../../../../../assets/titanic-11.png'"></app-image>

<app-callout><app-paragraph>Note that although the attribute "Embarked" is not numeric but categorical, if we apply the replacement by average, the result will be that the missing values will be replaced by the most popular data (S).</app-paragraph>
</app-callout>

<app-mini-sub-title>Outliers</app-mini-sub-title>

<app-paragraph>To correct the outliers, in this case which are few in number, what we will do is to delete the records that contain such data. In this case, the only attribute worth correcting is the "Fare" attribute. Based on the graph we obtained previously, the ideal at this point will be to filter out all the examples that do appear to be valid, which are, a priori, those under 400.00, so we will have a result similar to the following:</app-paragraph>

<app-image [image]="'../../../../../assets/titanic-12.png'"></app-image>

<app-paragraph>In this case, 3 tuples were detected that did not fit the indicated filter, and are considered outliers.</app-paragraph>

<app-image [image]="'../../../../../assets/titanic-13.png'"></app-image>

<app-mini-sub-title>Data scaling</app-mini-sub-title>

<app-paragraph>Finally, we need to adjust the scaling of certain attributes. We saw that the numeric attributes "<strong>Age</strong>", "****<u>SibSp</u>****", "<u>Parch</u>", "<u>Fare</u>", had different scales, and this can be detrimental to algorithms such as k-nn, because it would make certain attributes have a greater influence on the predictions. To solve this you have to normalize them, and in RapidMiner this can be done in the following way:</app-paragraph>

<app-image [image]="'../../../../../assets/titanic-14.png'"></app-image>

<app-paragraph>Obtaining, in this case, a result as follows:</app-paragraph>

<app-image [image]="'../../../../../assets/titanic-15.png'"></app-image>

<app-paragraph>Now the data have more or less the same scale, reducing the possible influence of this problem in the algorithms we use.</app-paragraph>

<app-callout>Note that the pre-defined transformation, "z-transformation," was used.</app-callout>

<app-paragraph>At this point, it should be clarified that in the final process, normalization will not be done before applying a separation of data for test and training, or in any case before applying cross validation. Rather, it will be done prior to these processes. This is to avoid the so-called "contamination" of data, where our models may contain information that they should not, giving us misleading results.</app-paragraph>

<app-mini-sub-title>Finalizing the preparation</app-mini-sub-title>

<app-paragraph>At this point, we already have a dataset, a priori, better than the one we had at the beginning. So now all that remains is to start testing this version of our data.</app-paragraph>

<app-sub-title>Modeling</app-sub-title>

<app-paragraph>Before we start modeling we have to recognize certain steps that we have to perform, such as:</app-paragraph>

<ul>
    <app-list-item>Determine which models will be most useful to us based on our type of problem.</app-list-item>
    <app-list-item>Determine if we will use any strategy to improve as much as possible the performance of our model.</app-list-item>
    <app-list-item>Determine what strategy we will use to evaluate the performance of these models.</app-list-item>
</ul>

<app-paragraph>So let's get to work.</app-paragraph>

<app-mini-sub-title>Model selection.</app-mini-sub-title>

<app-paragraph>First, before selecting any model, we have to identify the type of problem we have, in order to determine which algorithms we could use in this first iteration. In this case, as we said at the beginning of this work, we are facing a binary classification problem, since we want to determine whether a person survives or not.</app-paragraph>

<app-paragraph>To solve classification type problems, some algorithms that can be useful are:</app-paragraph>

<ul>
    <app-list-item>Naive bayes: It is always a good starting point to make use of this model.</app-list-item>
    <app-list-item>Logistic regression: Simple model and useful in two-class predictions.</app-list-item>
    <app-list-item>K-nn: Simple model that determines the distance between points to determine to which group a certain record belongs.</app-list-item>
</ul>

<app-paragraph>It must be taken into account that for each of these algorithms it will be necessary to make some modification in the data (data types for example).</app-paragraph>

<app-mini-sub-title>Determination of performance strategies</app-mini-sub-title>

<app-paragraph>We have some tools and strategies that we can use to make our models perform as well as possible. One of them is called "Feature Selection," where based on certain algorithms we determine the best possible combination of attributes to achieve better results.</app-paragraph>

<app-mini-sub-title>Performance evaluation</app-mini-sub-title>

<app-paragraph>This point is unavoidable. We will always want to know how our model behaves, and how well it does what we want it to do.</app-paragraph>

<app-paragraph>There are several strategies that we can use to measure the performance of a model, and some will be more or less useful than others, depending on our particular case. For this paper, we will consider two possible alternatives:</app-paragraph>

<ul>
    <app-list-item>Separate our dataset to use part of the data for training, and part for testing.</app-list-item>
    <app-list-item>Make use of the cross-validation strategy.</app-list-item>
</ul>

<app-paragraph>Both alternatives are widely used, the first one may be a bit more complex to fix because there are issues such as: What data to separate? How do I determine the data to separate? Did I get a good test or training set? Among others. So this time we will make use of the Cross-validation strategy.</app-paragraph>

<app-paragraph>Let's get to work!</app-paragraph>

<app-paragraph>First of all, what we have to do is to give the role of class/target variable to the attribute "Survived" since it is the one we want to predict.</app-paragraph>

<app-image [image]="'../../../../../assets/titanic-16.png'"></app-image>

<app-paragraph>Now, what we have to do is to determine which strategy we will use to improve the performance of our models. Among the ones we know at the moment is "Feature Selection," and among the different options we have to apply this strategy, we find:</app-paragraph>

<ul>
    <app-list-item>Brute Force</app-list-item>
    <app-list-item>Fordward Selection</app-list-item>
    <app-list-item>Backward Selection</app-list-item>
    <app-list-item>Evolutionary</app-list-item>
</ul>

<app-paragraph>We will see the advantages and disadvantages of each of them to select the ideal one:</app-paragraph>

<ul>
    <app-list-item><strong>Brute Force:</strong> It will provide us with the best possible combinations of attributes, but it will have an extremely high delay because it will try all possible combinations.</app-list-item>
    <app-list-item><strong>Fordward Selection:</strong> It is much better in terms of time compared to the previous one, but it has the disadvantage that we are not guaranteed the best possible combination.</app-list-item>
    <app-list-item><strong>Backward Selection:</strong> In general terms it is very similar to Fordward Selection.</app-list-item>
    <app-list-item><strong>Evolutionary:</strong> Evolutionary algorithm, it has better times than Brute Force and can provide better combinations than Fordward and Backward Selection. From the above, in this instance it seems that an Evolutionary type optimization is the best option.</app-list-item>
</ul>

<app-paragraph>Let's pass all of the above to RapidMiner:</app-paragraph>

<app-image [image]="'../../../../../assets/titanic-17.png'"></app-image>

<app-paragraph>This time we have the three "Feature Selection" operations, where within each one there is a cross validation as follows:</app-paragraph>

<app-image [image]="'../../../../../assets/titanic-18.png'"></app-image>

<app-sub-title>Evaluation</app-sub-title>

<app-paragraph>It is time to determine which of the trained models has the best performance. For this, a manual and basic, but at the same time effective and simple, tactic is to compare by "eye". So given the following results:</app-paragraph>

<app-mini-sub-title>Naive Bayes</app-mini-sub-title>

<app-image [image]="'../../../../../assets/titanic-20.png'"></app-image>

<app-mini-sub-title>Logistic Regression</app-mini-sub-title>

<app-image [image]="'../../../../../assets/titanic-21.png'"></app-image>

<app-mini-sub-title>K-NN</app-mini-sub-title>

<app-image [image]="'../../../../../assets/titanic-22.png'"></app-image>

<app-paragraph>It can be said that, of the algorithms used, K-NN is the one that generated the best performance.</app-paragraph>

<app-sub-title>Conclusions</app-sub-title>

<app-paragraph>As conclusions, we can say that although this is the first iteration, the results at first sight are, at least, satisfactory. But one thing is for sure, we must continue testing on the model obtained to explore the possibility of improving performance.</app-paragraph>
